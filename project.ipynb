{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZFNX2un6c76",
        "outputId": "2cb17e27-b1b1-4027-d5b9-6c56c2b479a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "7ZFNX2un6c76",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "940f61df-c803-4d2c-b1c5-021100375a27"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "from scipy.signal import butter, lfilter, freqz\n",
        "# from torch import nn, optim\n",
        "import sqlite3, os\n",
        "import math\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda\n",
        "from tensorflow.keras.losses import Huber, binary_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "id": "940f61df-c803-4d2c-b1c5-021100375a27",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a60038d9"
      },
      "source": [
        "pd.set_option('display.max_rows',100)"
      ],
      "id": "a60038d9",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d7b70f8-37dd-467e-a40f-beedc85dacdf"
      },
      "source": [
        "path = 'SisFall_dataset/'\n",
        "person = ['SA01','SA02','SA03','SA04','SA05','SA06','SA07','SA08','SA09','SA10','SA11','SA12','SA13','SA14','SA15','SA16','SA17','SA18','SA19','SA20']\n",
        "\n",
        "person2 = ['SA21','SA22','SA23']\n",
        "# person = ['data1','data3','data5','data7','data9','data11','data13','data15','data17','data19','data21','data23']\n",
        "# person = os.listdir(path)\n",
        "# person.pop(0)"
      ],
      "id": "1d7b70f8-37dd-467e-a40f-beedc85dacdf",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f7cddbd-5ee2-4dcf-9ac6-4082a251f274"
      },
      "source": [
        "# dailies = ['D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'D09', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15',\n",
        "#            'D16', 'D17', 'D18', 'D19']\n",
        "dailies = ['D04', 'D06']\n",
        "falls = ['F01', 'F02', 'F03', 'F04', 'F05', 'F06', 'F07', 'F08', 'F09', 'F10', 'F11', 'F12', 'F13', 'F14', 'F15']\n",
        "# falls = ['F01', 'F02', 'F03', 'F04']\n",
        "trials = ['R01', 'R02','R03','R04','R05']\n",
        "\n",
        "path = '/content/drive/MyDrive/sisfall_data/'"
      ],
      "id": "2f7cddbd-5ee2-4dcf-9ac6-4082a251f274",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ddbdaa4-bd99-4a76-83b8-fdcdbe9f1ec5"
      },
      "source": [
        "\n",
        "# Filter requirements.\n",
        "order = 4\n",
        "fs = 200.0  # sample rate, Hz\n",
        "cutoff = 5.0  # desired cutoff frequency of the filter, Hz\n",
        "\n",
        "\n",
        "# From??????\n",
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y"
      ],
      "id": "2ddbdaa4-bd99-4a76-83b8-fdcdbe9f1ec5",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac6807d9"
      },
      "source": [
        "def printer(df, min_max=True, range=[0,3000], *args):\n",
        "    idx = {}\n",
        "    if min_max:\n",
        "        x = df.drop(['activity','person'],axis=1).astype('float64')\n",
        "        k = (x - x.min()) / (x.max() - x.min())\n",
        "        for w in args:\n",
        "            plt.plot(k[w],label=w)\n",
        "            idx[w] = df[w][df[w] == df[w].max()].index.values\n",
        "        plt.title(f'person:{df.person[0]}  ,  activity:{df.activity[0]}')\n",
        "        plt.xlim(range)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        for w in idx:\n",
        "            print(f'{w} : {idx[w]}')\n",
        "    else:\n",
        "        for w in args:\n",
        "            plt.plot(df[w],label=w)\n",
        "        plt.title(df.activity[0])\n",
        "        plt.xlim(range)\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "id": "ac6807d9",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cda3d77"
      },
      "source": [
        "def preprocess(person):\n",
        "    subjectList = []\n",
        "    adl_list = []\n",
        "    fall_list = []\n",
        "    for man in person:\n",
        "        a = pd.read_csv(path + f'{man}.csv')\n",
        "        df = a[['ADXL_x', 'ADXL_y', 'ADXL_z', 'ITG_x', 'ITG_y', 'ITG_z', 'subject', 'activity', 'trial']]\n",
        "    #     df['ADXL_x'] *= (32/8192)\n",
        "    #     df['ADXL_y'] *= (32/8192)\n",
        "    #     df['ADXL_z'] *= (32/8192)\n",
        "        subjectList.append(df)\n",
        "    for s in subjectList:\n",
        "        for d in dailies:\n",
        "            tempdf = s[s['activity'] == d]\n",
        "            adl_list.append(tempdf)\n",
        "\n",
        "        for f in falls:\n",
        "            tempdf = s[s['activity'] == f]\n",
        "            fall_list.append(tempdf)\n",
        "            \n",
        "    return fall_list, adl_list\n",
        "    "
      ],
      "id": "9cda3d77",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92e2d023"
      },
      "source": [
        "def preprocess2(df):\n",
        "    df_list = []\n",
        "    rol_val = 50\n",
        "    for my_df in df:\n",
        "        for trial in trials:\n",
        "            trial_df = my_df[my_df['trial'] == trial]\n",
        "            if len(trial_df) == 0:\n",
        "                continue\n",
        "            trial_df.reset_index(inplace=True)\n",
        "            tempdf = pd.DataFrame()\n",
        "            tempdf['ax'], tempdf['ay'], tempdf['az'] = trial_df['ADXL_x'], trial_df['ADXL_y'], trial_df['ADXL_z']\n",
        "            tempdf = tempdf.reset_index(drop=True)\n",
        "            tempdf['fx'] = pd.Series(butter_lowpass_filter(trial_df['ADXL_x'], cutoff, fs, order))\n",
        "            tempdf['fy'] = pd.Series(butter_lowpass_filter(trial_df['ADXL_y'], cutoff, fs, order))\n",
        "            tempdf['fz'] = pd.Series(butter_lowpass_filter(trial_df['ADXL_z'], cutoff, fs, order))\n",
        "            tempdf['pitch'] = np.arctan(tempdf['fx'] / np.sqrt(tempdf['fy'] ** 2 + tempdf['fz'] ** 2)) * 180 / np.pi\n",
        "            tempdf['roll'] = np.arctan(tempdf['fy'] / np.sqrt(tempdf['fx'] ** 2 + tempdf['fz'] ** 2)) * 180 / np.pi\n",
        "            tempdf['theta'] = np.arctan(np.sqrt(tempdf['fy'] ** 2 + tempdf['fx'] ** 2) / tempdf['fz']) * 180 / np.pi\n",
        "            tempdf['angle_sum'] = np.sqrt(tempdf['pitch'] ** 2 + tempdf['roll'] ** 2 + tempdf['theta'] ** 2)\n",
        "            tempdf['vs'] = np.sqrt(tempdf['ax'] ** 2 + tempdf['ay'] ** 2 + tempdf['az'] ** 2)\n",
        "            tempdf['vm2'] =np.sqrt(tempdf['fx'] ** 2 + tempdf['fy'] ** 2 + tempdf['fz'] ** 2)\n",
        "\n",
        "            tempdf['bx'] = tempdf['fx'].diff()\n",
        "            tempdf['by'] = tempdf['fy'].diff()\n",
        "            tempdf['bz'] = tempdf['fz'].diff()\n",
        "            tempdf['diff_sum'] = np.sqrt(tempdf['bx'] ** 2 + tempdf['by'] ** 2 + tempdf['bz'] ** 2)\n",
        "            tempdf['activity'] = trial_df['activity']\n",
        "            tempdf['person'] = trial_df['subject']\n",
        "\n",
        "            tempdf = tempdf.reset_index(drop=True)\n",
        "            trial_df = trial_df.reset_index(drop=True)\n",
        "            tempdf['gx'], tempdf['gy'], tempdf['gz'] = trial_df['ITG_x'], trial_df['ITG_y'], trial_df['ITG_z']\n",
        "            tempdf['g_fx'] = pd.Series(butter_lowpass_filter(tempdf['gx'], cutoff, fs, order))\n",
        "            tempdf['g_fy'] = pd.Series(butter_lowpass_filter(tempdf['gy'], cutoff, fs, order))\n",
        "            tempdf['g_fz'] = pd.Series(butter_lowpass_filter(tempdf['gz'], cutoff, fs, order))\n",
        "            tempdf['g_sum'] = np.sqrt(tempdf['g_fx'] ** 2 + tempdf['g_fy'] ** 2 + tempdf['g_fz'] ** 2)\n",
        "\n",
        "#             # Rolling averages\n",
        "#             tempdf['y_roll'] = pd.Series(tempdf['by'].rolling(rol_val).mean())\n",
        "#             tempdf['fy_roll'] = pd.Series(tempdf['fy'].rolling(rol_val).mean())\n",
        "#             tempdf['gy_roll'] = pd.Series(tempdf['by'].rolling(rol_val).mean())\n",
        "\n",
        "#             tempdf['gx_pitch'] = (tempdf['g_fx'].rolling(2).mean() * (1/200))\n",
        "#             tempdf['gy_pitch'] = (tempdf['g_fy'].rolling(2).mean() * (1/200))\n",
        "#             tempdf['gz_pitch'] = (tempdf['g_fz'].rolling(2).mean() * (1/200))\n",
        "\n",
        "\n",
        "            # Rolling standard deviations\n",
        "#             tempdf['bx_std'] = tempdf['bx'].rolling(rol_val,min_periods = 1).std()\n",
        "#             tempdf['by_std'] = tempdf['by'].rolling(rol_val,min_periods = 1).std()\n",
        "#             tempdf['bz_std'] = tempdf['bz'].rolling(rol_val,min_periods = 1).std()\n",
        "#             tempdf['fx_std'] = tempdf['fx'].rolling(rol_val,min_periods = 1).std()\n",
        "#             tempdf['fy_std'] = tempdf['fy'].rolling(rol_val,min_periods = 1).std()\n",
        "#             tempdf['fz_std'] = tempdf['fz'].rolling(rol_val,min_periods = 1).std()\n",
        "#             tempdf['gx_std'] = tempdf['gx'].rolling(rol_val,min_periods = 1).std()\n",
        "#             tempdf['gy_std'] = tempdf['gy'].rolling(rol_val,min_periods = 1).std()\n",
        "#             tempdf['gz_std'] = tempdf['gz'].rolling(rol_val,min_periods = 1).std()\n",
        "\n",
        "\n",
        "            # Integral stuff\n",
        "#             tempdf['xsum'] = ((abs(tempdf['ax']).rolling(2).sum() / 2) * (1 / 200)).fillna(0).expanding().sum()\n",
        "#             tempdf['ysum'] = ((abs(tempdf['ay']).rolling(2).sum() / 2) * (1 / 200)).fillna(0).expanding().sum()\n",
        "#             tempdf['zsum'] = ((abs(tempdf['az']).rolling(2).sum() / 2) * (1 / 200)).fillna(0).expanding().sum()\n",
        "#             tempdf['time'] = 1 / 200\n",
        "#             tempdf['time'] = tempdf['time'].expanding().sum()\n",
        "#             # C10 Signal Magnitude Area\n",
        "#             tempdf['SigMagArea'] = (tempdf['xsum'] + tempdf['ysum'] + tempdf['zsum']) / tempdf['time']\n",
        "#             # C11\n",
        "#             tempdf['HorizSigMagArea'] = (tempdf['xsum'] + tempdf['zsum']) / tempdf['time']\n",
        "            # C1\n",
        "\n",
        "#             tempdf['vm'] = np.sqrt(((np.sqrt(tempdf['fx'] ** 2 + tempdf['fy'] ** 2 + tempdf['fz'] ** 2)) ** 2).rolling(rol_val).mean())\n",
        "#             # Maximum peak to peak acceleration amplitude\n",
        "#             tempdf['Amax'] = (tempdf['vm'].rolling(rol_val).max())\n",
        "#             tempdf['Amin'] = (tempdf['vm'].rolling(rol_val).min())\n",
        "#             # C3\n",
        "#             tempdf['peak_diff'] = tempdf['Amax'] - tempdf['Amin']\n",
        "#             # C4\n",
        "#             tempdf['angle_from_horiz'] = np.arctan2(np.sqrt(tempdf['fx'] ** 2 + tempdf['fz'] ** 2), -tempdf['fy']) * 180 / np.pi\n",
        "#             tempdf['angle_std'] = tempdf['angle_from_horiz'].rolling(rol_val).std()\n",
        "\n",
        "#             # had to make versions of this to put into sliding window, will change once I\n",
        "#             # confirm they're the same as the others below\n",
        "#             #C8\n",
        "#             tempdf['horiz_std_mag9'] = np.sqrt(tempdf['fx_std'] ** 2 + tempdf['fz_std'] ** 2)\n",
        "#             #C2\n",
        "#             tempdf['horiz_vector_mag9'] = np.sqrt(tempdf['fx'] ** 2 + tempdf['fz'] ** 2)\n",
        "#             tempdf['std_mag9'] = np.sqrt(tempdf['fx_std'] ** 2 + tempdf['fy_std'] ** 2 + tempdf['fz_std'] ** 2)\n",
        "#             #C9\n",
        "#             tempdf['diff_std_mag9'] = np.sqrt(tempdf['bx_std'] ** 2 + tempdf['by_std'] ** 2 + tempdf['bz_std'] ** 2)\n",
        "#             tempdf['horiz_mag2'] = np.sqrt(tempdf['bx'] ** 2 + tempdf['bz'] ** 2)\n",
        "#             tempdf['horiz_std_mag2'] = np.sqrt(tempdf['bx_std'] ** 2 + tempdf['bz_std'] ** 2)\n",
        "#             tempdf['vector_mag2'] = np.sqrt(tempdf['bx'] ** 2 + tempdf['by'] ** 2 + tempdf['bz'] ** 2)\n",
        "#             tempdf['gyro_horiz_std_mag'] = np.sqrt(tempdf['gx_std'] ** 2 + tempdf['gz_std'] ** 2)\n",
        "#             tempdf['gyro_vector_mag'] = np.sqrt(tempdf['gx'] ** 2 + tempdf['gy'] ** 2 + tempdf['gz'] ** 2)\n",
        "#             tempdf['gyro_horiz_mag'] = np.sqrt(tempdf['gx'] ** 2 + tempdf['gz'] ** 2)\n",
        "#             tempdf['gyro_std_mag'] = np.sqrt(tempdf['gx_std'] ** 2 + tempdf['gy_std'] ** 2 + tempdf['gz_std'] ** 2)\n",
        "#             tempdf['vector_mag'] = np.sqrt(tempdf['fx'] ** 2 + tempdf['fy'] ** 2 + tempdf['fz'] ** 2)\n",
        "#             # C2\n",
        "#             tempdf['horiz_mag'] = np.sqrt(tempdf['fx'] ** 2 + tempdf['fz'] ** 2)\n",
        "#             #\n",
        "#             tempdf['vert'] = tempdf['by'] - tempdf['y_roll']\n",
        "#             tempdf['vert2'] = tempdf['ay'] - tempdf['y_roll']\n",
        "#             tempdf['vert3'] = tempdf['fy'] - tempdf['fy_roll']\n",
        "#             # C9\n",
        "#             tempdf['std_mag2'] = np.sqrt(tempdf['bx_std'] ** 2 + tempdf['by_std'] ** 2 + tempdf['bz_std'] ** 2)\n",
        "            df_list.append(tempdf.fillna(0))\n",
        "    return df_list"
      ],
      "id": "92e2d023",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b33430f"
      },
      "source": [
        "def labeling(fall_list,adl_list, standard,min_max, check_list):\n",
        "    adl_df = []\n",
        "    fall_df = []\n",
        "\n",
        "    for df in fall_list:\n",
        "        df = df.loc[:,check_list]\n",
        "        if min_max:\n",
        "            df = (df - df.min()) / (df.max() - df.min())\n",
        "\n",
        "        k = df[standard].idxmax()\n",
        "        fall = df.loc[k - 120 : k]\n",
        "        fall['label'] = 1\n",
        "        fall_df.append(fall)\n",
        "    \n",
        "    for df in adl_list:\n",
        "        df = df.loc[120:,check_list]\n",
        "        if min_max:\n",
        "            df = (df - df.min()) / (df.max() - df.min())\n",
        "        df['label'] = 0\n",
        "        adl_df.append(df)\n",
        "\n",
        "    return fall_df, adl_df"
      ],
      "id": "6b33430f",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73823270"
      },
      "source": [
        "def windowing(fall_df,adl_df , WINDOWSIZE):\n",
        "    x = []\n",
        "    y = []\n",
        "    for df in fall_df:\n",
        "        for i in range(len(df) - WINDOWSIZE):\n",
        "            df_x = df.drop('label',axis=1).iloc[i : i+ WINDOWSIZE]\n",
        "            df_y = df['label'].iloc[1]\n",
        "            x.append(df_x)\n",
        "            y.append(df_y)\n",
        "    for df in adl_df:\n",
        "        count = 0\n",
        "        for i in range(120,len(df) - WINDOWSIZE,20):\n",
        "            count += 1\n",
        "            df_x = df.drop('label',axis=1).iloc[i : i+ WINDOWSIZE]\n",
        "            df_y = df['label'].iloc[1]\n",
        "            x.append(df_x)\n",
        "            y.append(df_y)\n",
        "            if count > 120:\n",
        "                break\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state = 0)\n",
        "    return x_train, x_valid, y_train, y_valid"
      ],
      "id": "73823270",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72e9a3a8"
      },
      "source": [
        "WINDOWSIZE = 60"
      ],
      "id": "72e9a3a8",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a29854d1"
      },
      "source": [
        "# preprocess\n",
        "fall_list, adl_list = preprocess(person)\n",
        "fall_list = preprocess2(fall_list)\n",
        "adl_list = preprocess2(adl_list)"
      ],
      "id": "a29854d1",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fdc5bbe"
      },
      "source": [
        "fall_df, adl_df = labeling(fall_list,adl_list,'vm2',1, ['g_sum','diff_sum','vm2'])"
      ],
      "id": "9fdc5bbe",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1775cd40"
      },
      "source": [
        "x_train, x_valid, y_train, y_valid = windowing(fall_df , adl_df, 60)"
      ],
      "id": "1775cd40",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4342497"
      },
      "source": [
        "# model = tf.keras.models.Sequential([\n",
        "#     # 1차원 feature map 생성\n",
        "# #     tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n",
        "# #            padding=\"causal\",\n",
        "# #            activation=\"relu\",dff\n",
        "# #            input_shape=[WINDOW_SIZE, 4]),\n",
        "#     # LSTM\n",
        "#     tf.keras.layers.LSTM(128,input_shape=[WINDOWSIZE, 3], activation='tanh', return_sequences=True ),\n",
        "#     tf.keras.layers.LSTM(64,  return_sequences=True ),\n",
        "#     tf.keras.layers.LSTM(32),\n",
        "#     tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "#     tf.keras.layers.Dense(8, activation=\"relu\"),\n",
        "#     tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "# ])"
      ],
      "id": "e4342497",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c780a542"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # 1차원 feature map 생성\n",
        "#     tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n",
        "#            padding=\"causal\",\n",
        "#            activation=\"relu\",dff\n",
        "#            input_shape=[WINDOW_SIZE, 4]),\n",
        "    # LSTM\n",
        "    tf.keras.layers.LSTM(128,input_shape=[WINDOWSIZE, 3], activation='tanh', return_sequences=True),\n",
        "    tf.keras.layers.LSTM(64,  return_sequences=True,dropout=0.2 ),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(8, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "])"
      ],
      "id": "c780a542",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d899a9d",
        "outputId": "8f3b19e7-39c9-42f6-c5fa-97741e9ba8c7"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer='adam', metrics='accuracy')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=15)\n",
        "filename = os.path.join('tmp_checkpoint.h5')\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "history = model.fit(x_train, y_train, \n",
        "                    epochs=100, \n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_valid, y_valid), \n",
        "                    callbacks=[early_stop, checkpoint])"
      ],
      "id": "7d899a9d",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.3519 - accuracy: 0.8760\n",
            "Epoch 00001: val_loss improved from inf to 0.26399, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 44s 14ms/step - loss: 0.3519 - accuracy: 0.8760 - val_loss: 0.2640 - val_accuracy: 0.9155\n",
            "Epoch 2/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.1712 - accuracy: 0.9396\n",
            "Epoch 00002: val_loss improved from 0.26399 to 0.15727, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 36s 14ms/step - loss: 0.1711 - accuracy: 0.9397 - val_loss: 0.1573 - val_accuracy: 0.9477\n",
            "Epoch 3/100\n",
            "2613/2616 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.9594\n",
            "Epoch 00003: val_loss improved from 0.15727 to 0.08697, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.1127 - accuracy: 0.9594 - val_loss: 0.0870 - val_accuracy: 0.9686\n",
            "Epoch 4/100\n",
            "2612/2616 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 0.9696\n",
            "Epoch 00004: val_loss improved from 0.08697 to 0.07737, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0839 - accuracy: 0.9696 - val_loss: 0.0774 - val_accuracy: 0.9731\n",
            "Epoch 5/100\n",
            "2613/2616 [============================>.] - ETA: 0s - loss: 0.0715 - accuracy: 0.9738\n",
            "Epoch 00005: val_loss did not improve from 0.07737\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0715 - accuracy: 0.9738 - val_loss: 0.1488 - val_accuracy: 0.9523\n",
            "Epoch 6/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0616 - accuracy: 0.9774\n",
            "Epoch 00006: val_loss improved from 0.07737 to 0.05102, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0615 - accuracy: 0.9774 - val_loss: 0.0510 - val_accuracy: 0.9815\n",
            "Epoch 7/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0551 - accuracy: 0.9799\n",
            "Epoch 00007: val_loss improved from 0.05102 to 0.04268, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0551 - accuracy: 0.9799 - val_loss: 0.0427 - val_accuracy: 0.9854\n",
            "Epoch 8/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9823\n",
            "Epoch 00008: val_loss did not improve from 0.04268\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0484 - accuracy: 0.9823 - val_loss: 0.0436 - val_accuracy: 0.9841\n",
            "Epoch 9/100\n",
            "2613/2616 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.9835\n",
            "Epoch 00009: val_loss improved from 0.04268 to 0.03729, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0461 - accuracy: 0.9835 - val_loss: 0.0373 - val_accuracy: 0.9870\n",
            "Epoch 10/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0409 - accuracy: 0.9856\n",
            "Epoch 00010: val_loss did not improve from 0.03729\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0409 - accuracy: 0.9856 - val_loss: 0.0420 - val_accuracy: 0.9863\n",
            "Epoch 11/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9864\n",
            "Epoch 00011: val_loss improved from 0.03729 to 0.03486, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0388 - accuracy: 0.9864 - val_loss: 0.0349 - val_accuracy: 0.9869\n",
            "Epoch 12/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9865\n",
            "Epoch 00012: val_loss improved from 0.03486 to 0.03140, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0370 - accuracy: 0.9865 - val_loss: 0.0314 - val_accuracy: 0.9889\n",
            "Epoch 13/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9880\n",
            "Epoch 00013: val_loss did not improve from 0.03140\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0340 - accuracy: 0.9880 - val_loss: 0.0331 - val_accuracy: 0.9876\n",
            "Epoch 14/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9883\n",
            "Epoch 00014: val_loss improved from 0.03140 to 0.03089, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0331 - accuracy: 0.9883 - val_loss: 0.0309 - val_accuracy: 0.9897\n",
            "Epoch 15/100\n",
            "2612/2616 [============================>.] - ETA: 0s - loss: 0.0304 - accuracy: 0.9892\n",
            "Epoch 00015: val_loss did not improve from 0.03089\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0304 - accuracy: 0.9892 - val_loss: 0.0330 - val_accuracy: 0.9888\n",
            "Epoch 16/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9900\n",
            "Epoch 00016: val_loss did not improve from 0.03089\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.0493 - val_accuracy: 0.9832\n",
            "Epoch 17/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9906\n",
            "Epoch 00017: val_loss did not improve from 0.03089\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.0349 - val_accuracy: 0.9870\n",
            "Epoch 18/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9906\n",
            "Epoch 00018: val_loss improved from 0.03089 to 0.02641, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.0264 - val_accuracy: 0.9914\n",
            "Epoch 19/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9915\n",
            "Epoch 00019: val_loss improved from 0.02641 to 0.02444, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.0244 - val_accuracy: 0.9916\n",
            "Epoch 20/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9919\n",
            "Epoch 00020: val_loss did not improve from 0.02444\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0229 - accuracy: 0.9919 - val_loss: 0.0272 - val_accuracy: 0.9908\n",
            "Epoch 21/100\n",
            "2612/2616 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9923\n",
            "Epoch 00021: val_loss improved from 0.02444 to 0.02118, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 0.0212 - val_accuracy: 0.9941\n",
            "Epoch 22/100\n",
            "2613/2616 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9934\n",
            "Epoch 00022: val_loss improved from 0.02118 to 0.02056, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.0206 - val_accuracy: 0.9935\n",
            "Epoch 23/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9930\n",
            "Epoch 00023: val_loss did not improve from 0.02056\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.0252 - val_accuracy: 0.9925\n",
            "Epoch 24/100\n",
            "2612/2616 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9937\n",
            "Epoch 00024: val_loss improved from 0.02056 to 0.01951, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.0195 - val_accuracy: 0.9942\n",
            "Epoch 25/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9938\n",
            "Epoch 00025: val_loss improved from 0.01951 to 0.01914, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0191 - val_accuracy: 0.9943\n",
            "Epoch 26/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9946\n",
            "Epoch 00026: val_loss did not improve from 0.01914\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0221 - val_accuracy: 0.9934\n",
            "Epoch 27/100\n",
            "2612/2616 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9942\n",
            "Epoch 00027: val_loss did not improve from 0.01914\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.0239 - val_accuracy: 0.9932\n",
            "Epoch 28/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9947\n",
            "Epoch 00028: val_loss improved from 0.01914 to 0.01698, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0170 - val_accuracy: 0.9957\n",
            "Epoch 29/100\n",
            "2613/2616 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9940\n",
            "Epoch 00029: val_loss did not improve from 0.01698\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.0176 - val_accuracy: 0.9949\n",
            "Epoch 30/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9953\n",
            "Epoch 00030: val_loss did not improve from 0.01698\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0240 - val_accuracy: 0.9931\n",
            "Epoch 31/100\n",
            "2613/2616 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9948\n",
            "Epoch 00031: val_loss improved from 0.01698 to 0.01615, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 0.0161 - val_accuracy: 0.9952\n",
            "Epoch 32/100\n",
            "2612/2616 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9954\n",
            "Epoch 00032: val_loss did not improve from 0.01615\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0214 - val_accuracy: 0.9941\n",
            "Epoch 33/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9954\n",
            "Epoch 00033: val_loss did not improve from 0.01615\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0187 - val_accuracy: 0.9957\n",
            "Epoch 34/100\n",
            "2612/2616 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9958\n",
            "Epoch 00034: val_loss did not improve from 0.01615\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0207 - val_accuracy: 0.9943\n",
            "Epoch 35/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9959\n",
            "Epoch 00035: val_loss did not improve from 0.01615\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0270 - val_accuracy: 0.9901\n",
            "Epoch 36/100\n",
            "2613/2616 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9959\n",
            "Epoch 00036: val_loss did not improve from 0.01615\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0162 - val_accuracy: 0.9957\n",
            "Epoch 37/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9961\n",
            "Epoch 00037: val_loss improved from 0.01615 to 0.01609, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0161 - val_accuracy: 0.9958\n",
            "Epoch 38/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9963\n",
            "Epoch 00038: val_loss did not improve from 0.01609\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0254 - val_accuracy: 0.9940\n",
            "Epoch 39/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9965\n",
            "Epoch 00039: val_loss improved from 0.01609 to 0.01474, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0147 - val_accuracy: 0.9963\n",
            "Epoch 40/100\n",
            "2613/2616 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9963\n",
            "Epoch 00040: val_loss did not improve from 0.01474\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0151 - val_accuracy: 0.9954\n",
            "Epoch 41/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9965\n",
            "Epoch 00041: val_loss did not improve from 0.01474\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.0170 - val_accuracy: 0.9956\n",
            "Epoch 42/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9967\n",
            "Epoch 00042: val_loss did not improve from 0.01474\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0175 - val_accuracy: 0.9961\n",
            "Epoch 43/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9967\n",
            "Epoch 00043: val_loss did not improve from 0.01474\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0158 - val_accuracy: 0.9961\n",
            "Epoch 44/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9966\n",
            "Epoch 00044: val_loss did not improve from 0.01474\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.0161 - val_accuracy: 0.9956\n",
            "Epoch 45/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9967\n",
            "Epoch 00045: val_loss did not improve from 0.01474\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.0194 - val_accuracy: 0.9952\n",
            "Epoch 46/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9970\n",
            "Epoch 00046: val_loss did not improve from 0.01474\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.0187 - val_accuracy: 0.9963\n",
            "Epoch 47/100\n",
            "2612/2616 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9974\n",
            "Epoch 00047: val_loss did not improve from 0.01474\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0159 - val_accuracy: 0.9964\n",
            "Epoch 48/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.9967\n",
            "Epoch 00048: val_loss improved from 0.01474 to 0.01276, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.0128 - val_accuracy: 0.9966\n",
            "Epoch 49/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9975\n",
            "Epoch 00049: val_loss did not improve from 0.01276\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0167 - val_accuracy: 0.9964\n",
            "Epoch 50/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9971\n",
            "Epoch 00050: val_loss did not improve from 0.01276\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.0164 - val_accuracy: 0.9964\n",
            "Epoch 51/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9976\n",
            "Epoch 00051: val_loss did not improve from 0.01276\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0195 - val_accuracy: 0.9950\n",
            "Epoch 52/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9978\n",
            "Epoch 00052: val_loss did not improve from 0.01276\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0166 - val_accuracy: 0.9961\n",
            "Epoch 53/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9972\n",
            "Epoch 00053: val_loss did not improve from 0.01276\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.0231 - val_accuracy: 0.9938\n",
            "Epoch 54/100\n",
            "2613/2616 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9976\n",
            "Epoch 00054: val_loss did not improve from 0.01276\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0352 - val_accuracy: 0.9888\n",
            "Epoch 55/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9976\n",
            "Epoch 00055: val_loss did not improve from 0.01276\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0219 - val_accuracy: 0.9954\n",
            "Epoch 56/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9978\n",
            "Epoch 00056: val_loss did not improve from 0.01276\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0215 - val_accuracy: 0.9939\n",
            "Epoch 57/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9978\n",
            "Epoch 00057: val_loss improved from 0.01276 to 0.01094, saving model to tmp_checkpoint.h5\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0109 - val_accuracy: 0.9975\n",
            "Epoch 58/100\n",
            "2613/2616 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981\n",
            "Epoch 00058: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0219 - val_accuracy: 0.9942\n",
            "Epoch 59/100\n",
            "2612/2616 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9977\n",
            "Epoch 00059: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0279 - val_accuracy: 0.9921\n",
            "Epoch 60/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982\n",
            "Epoch 00060: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0148 - val_accuracy: 0.9965\n",
            "Epoch 61/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9982\n",
            "Epoch 00061: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0135 - val_accuracy: 0.9971\n",
            "Epoch 62/100\n",
            "2613/2616 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9984\n",
            "Epoch 00062: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0280 - val_accuracy: 0.9951\n",
            "Epoch 63/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9980\n",
            "Epoch 00063: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0263 - val_accuracy: 0.9952\n",
            "Epoch 64/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9981\n",
            "Epoch 00064: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0184 - val_accuracy: 0.9963\n",
            "Epoch 65/100\n",
            "2612/2616 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9983\n",
            "Epoch 00065: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0139 - val_accuracy: 0.9971\n",
            "Epoch 66/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982\n",
            "Epoch 00066: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 34s 13ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0137 - val_accuracy: 0.9968\n",
            "Epoch 67/100\n",
            "2616/2616 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9960\n",
            "Epoch 00067: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0149 - val_accuracy: 0.9965\n",
            "Epoch 68/100\n",
            "2615/2616 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984\n",
            "Epoch 00068: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0200 - val_accuracy: 0.9960\n",
            "Epoch 69/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9985\n",
            "Epoch 00069: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0665 - val_accuracy: 0.9832\n",
            "Epoch 70/100\n",
            "2612/2616 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9896\n",
            "Epoch 00070: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0255 - accuracy: 0.9896 - val_loss: 0.0318 - val_accuracy: 0.9945\n",
            "Epoch 71/100\n",
            "2614/2616 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9984\n",
            "Epoch 00071: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0117 - val_accuracy: 0.9973\n",
            "Epoch 72/100\n",
            "2612/2616 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
            "Epoch 00072: val_loss did not improve from 0.01094\n",
            "2616/2616 [==============================] - 35s 13ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0182 - val_accuracy: 0.9960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed9e4b73",
        "outputId": "d82b125f-64d6-4c9f-d8ea-5da087dc75da"
      },
      "source": [
        "score = model.evaluate(x_train,y_train)\n",
        "print(score[1])\n",
        "print(score[0])\n",
        "# p = pd.DataFrame(pre.round())\n",
        "# p\n",
        "# x = pd.DataFrame(y_train)\n",
        "# t = pd.concat([p,x],axis=1)\n",
        "# (t.iloc[:,1] + t.iloc[:,0]).value_counts()"
      ],
      "id": "ed9e4b73",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2616/2616 [==============================] - 15s 6ms/step - loss: 0.0031 - accuracy: 0.9990\n",
            "0.9989844560623169\n",
            "0.0031398062128573656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6644a2ed"
      },
      "source": [
        "fall_list, adl_list = preprocess(person2)\n",
        "fall_list = preprocess2(fall_list)\n",
        "adl_list = preprocess2(adl_list)"
      ],
      "id": "6644a2ed",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cf5ec76"
      },
      "source": [
        "##test data\n",
        "test_list = []\n",
        "for df in fall_list:\n",
        "    df = df[['g_sum','diff_sum','vm2']]\n",
        "    df = (df - df.min()) / (df.max() - df.min())\n",
        "    df['label'] = 0\n",
        "    k = df.g_sum.idxmax()\n",
        "    df['label'].loc[k-60:k] = 1\n",
        "    df = df.loc[200:k]\n",
        "    test_list.append(df)\n",
        "for df in adl_list:\n",
        "    df = df[['g_sum','diff_sum','vm2']]\n",
        "    df = (df - df.min()) / (df.max() - df.min())\n",
        "    df['label'] = 0\n",
        "    df = df.loc[200:]\n",
        "    test_list.append(df)\n",
        "\n",
        "test_x = []\n",
        "test_y = []\n",
        "WINDOWSIZE = 60\n",
        "for df in test_list:\n",
        "    for i in range(len(df) - WINDOWSIZE):\n",
        "        df_x = df.drop('label',axis=1).iloc[i : i+ WINDOWSIZE]\n",
        "        df_y = df['label'].iloc[i+WINDOWSIZE]\n",
        "        test_x.append(df_x)\n",
        "        test_y.append(df_y)\n",
        "\n",
        "np_x = np.array(test_x)\n",
        "np_y = np.array(test_y)\n",
        "    "
      ],
      "id": "0cf5ec76",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8013c62a"
      },
      "source": [
        "score = model.evaluate(np_x,np_y)\n"
      ],
      "id": "8013c62a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWctHDZw7Ndi"
      },
      "source": [
        "score"
      ],
      "id": "dWctHDZw7Ndi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFwxJVrD7OXp"
      },
      "source": [
        ""
      ],
      "id": "vFwxJVrD7OXp",
      "execution_count": null,
      "outputs": []
    }
  ]
}